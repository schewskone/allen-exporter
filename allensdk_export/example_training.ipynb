{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8379a594-a7c8-4af3-9ee5-4e5fbab5a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from experanto.datasets import ChunkDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1953158d-c7ae-4095-9e59-b67d0a19511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = '../data/example_experiment'\n",
    "sampling_rate = 30  # Timestamps generated by this do not match the real ones, why do this? Is this for output data?\n",
    "chunk_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6c6d219-6a13-49eb-8574-aae1248c797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ChunkDataset(root_folder=root_folder, global_sampling_rate=sampling_rate,\n",
    "            global_chunk_size=chunk_size,\n",
    "            modality_config = \n",
    "            {'screen': {\n",
    "                'sampling_rate': None,\n",
    "                'chunk_size': None,\n",
    "                'valid_condition': {\n",
    "                    'tier': 'train',\n",
    "                    'stim_type': 'stimulus.Frame', #include both images and videos\n",
    "                    'stim_type': 'stimulus.Clip'\n",
    "                },\n",
    "                'offset': 0,\n",
    "                'sample_stride': 4,\n",
    "                # necessary for the allen dataset since there are blanks after every stimuli because else no valid times are found\n",
    "                'include_blanks': True, \n",
    "                'transforms': {\n",
    "                    'ToTensor': {\n",
    "                        '_target_': 'torchvision.transforms.ToTensor'\n",
    "                    },\n",
    "                    'Normalize': {\n",
    "                        '_target_': 'torchvision.transforms.Normalize',\n",
    "                        'mean': 80.0,\n",
    "                        'std': 60.0\n",
    "                    },\n",
    "                    'Resize': {\n",
    "                        '_target_': 'torchvision.transforms.Resize',\n",
    "                        'size': [144, 256]\n",
    "                    },\n",
    "                    'CenterCrop': {\n",
    "                        '_target_': 'torchvision.transforms.CenterCrop',\n",
    "                        'size': 144\n",
    "                    }\n",
    "                },\n",
    "                'interpolation': {}\n",
    "            },\n",
    "            'responses': {\n",
    "                'sampling_rate': None,\n",
    "                'chunk_size': None,\n",
    "                'offset': 0.1,\n",
    "                'transforms': {\n",
    "                    'standardize': True\n",
    "                },\n",
    "                'interpolation': {\n",
    "                    'interpolation_mode': 'nearest_neighbor'\n",
    "                }\n",
    "            },\n",
    "            'eye_tracker': {\n",
    "                'sampling_rate': None,\n",
    "                'chunk_size': None,\n",
    "                'offset': 0,\n",
    "                'transforms': {\n",
    "                    'normalize': True\n",
    "                },\n",
    "                'interpolation': {\n",
    "                    'interpolation_mode': 'nearest_neighbor'\n",
    "                }\n",
    "            },\n",
    "            'treadmill': {\n",
    "                'sampling_rate': None,\n",
    "                'chunk_size': None,\n",
    "                'offset': 0,\n",
    "                'transforms': {\n",
    "                    'normalize': True\n",
    "                },\n",
    "                'interpolation': {\n",
    "                    'interpolation_mode': 'nearest_neighbor'\n",
    "                }\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab29670d-fcb5-4d89-9216-8e82652ba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "data_loaders = OrderedDict()\n",
    "m = 'example_experiment'\n",
    "\n",
    "data_loaders['train'] = OrderedDict()\n",
    "#data_loaders['oracle'] = OrderedDict()\n",
    "data_loaders['train'][m] =  DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#data_loaders['oracle'][m] = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "it =next(iter(data_loaders['train'][m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48774bb8-929e-4426-96b4-93ee28db6aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is shape of eye_tracker : torch.Size([1, 20, 22])\n",
      "This is shape of screen : torch.Size([1, 20, 1, 144, 144])\n",
      "This is shape of treadmill : torch.Size([1, 20, 1])\n",
      "This is shape of responses : torch.Size([1, 20, 12])\n",
      "This is shape of timestamps : torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "for key in it.keys():\n",
    "    print(f\"This is shape of {key} : {it[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7242b8-9982-48c9-bfda-fa86f1fb82f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
